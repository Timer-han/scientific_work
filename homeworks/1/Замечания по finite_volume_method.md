Замечания по finite_volume_method.py:
1. Добавить функцию точного решения, например, sol_ex; тогда значения граничных условий a, b можно вычислять как sol_ex(0), sol_ex(length) или даже просто заменить в коде a, b на эти выражения
2. Переделать прогонку, чтобы принимала три массива с диагоналями
3. Функцию get_initial_data стоит переименовать, чтобы название отражало ее предназначение
4. Когда рисуются графики, то в качестве значения x берется np.linspace(0, lengh, n - 1). Если мы возьмем length = 1, n = 4, то эта штука будет равна `[0.  0.5 1. ]`, что не совсем правильно. В таком случае у нас 4 ячейки, и данные должны располагаться в их центрах (так как у нас МКО). cell_size = 1/4 = 0.25, тогда коордианты должны быть [0.125, 0.375, 0.625, 0.875]. То есть как-то так: np.linspace(cell_size/2, length-cell_size/2, n)
5. Да и get_tridiagonal_matrix должна принимать n, а не n-1. По-видимому, n-1 осталось от кода по МКР
6. Опционально: можно не делать столь длинные и подробные названия переменных. Если нравится, то хорошо, но если вдруг это опасение непонятных переменных, то ничего страшного, можно укорачивать
7. Когда в коде будет задано аналитическое решение, то надо еще приделать вычисление ошибки, например, ее С-нормы, то есть максимального отклонения от аналитики. После этого провести расчеты на последовательности измельчающихся сеток, например, N = 16, 32, 64... и построить график ошибки в зависимости от dx. Как правило, в задачах такого рода ошибка имеет порядок O(dx^m), m = 2 тут. График ошибки в таком случае хорошо строить в loglog-шкале, он должен иметь вид прямой линии и по наклону даже на глаз можно прикидывать m

Там на графиках идет сравнение решения прогонкой и функцией полного обращения матрицы. Я бы сравнивал скорее решение прогонкой с аналитическим решением. То есть, рядом с func задавал бы другую функцию, например, sol_ex, в которую записывал бы аналитическое решение, на котором тестируемся. А в func записывал бы правую часть от него, то есть, минус вторую производную. Например, sol_ex = x\*x, func = -2. Или sol_ex = sin(x), func = sin(x). И отрисовывал бы потом sol_ex и полученное численное решение

Еще насчет представления матриц. Поскольку у нас тут задача одномерная и матрицы всегда трехдиагональные, их можно хранить не в виде прямо матрицы NxN, а хранить каждую диагональ в виде массива. Таким образом, вместо N*N памяти нам понадобится всего 3*N-2 элемента. Это типичная ситуация для матриц, которые возникают в таких вот задачах для частных производных. Они обычно являются разреженными (sparse matrix), то есть, состоят по большей части из нулей, а ненулевых элементов там где-то O(N). Иногда матрицы имеют структуру (трехдиагональные, как в этой задаче, пятидиагональные в двумерных задачах с квадратной сеткой), и легко придумать формат хранения, а иногда структуры явной нет, но ненулевых элементов все равно O(N). Есть форматы общего назначения в таких случаях, например, compressed sparse row (https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0), или compressed sparse column (в tNavigator вроде какая-то его своя модификация используется)

Да. Здесь не хватает граничных условий (начальные условия - это когда есть время). Можно пока принять их, как в (3), то есть, если говорить в терминах фильтрации, задан напор: h(0) = a, h(L) = b